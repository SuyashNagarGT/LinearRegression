📏 Understanding R-Squared in Multiple Linear Regression
R-squared (R²) is a key metric in regression analysis. It tells us how well the independent variables explain the variation in the dependent variable.

🔍 What Does R-Squared Represent?

R² = 0 → The model explains none of the variability in the outcome.
R² = 1 → The model explains all the variability perfectly.
Higher R² → Better fit of the model to the data.


💡 Think of R² as a percentage:
If R² = 0.85, then 85% of the variation in the dependent variable is explained by the model.


📈 Behavior of R-Squared

✅ Always increases when you add more predictors — even if they’re not useful.
⚠️ This can be misleading! That’s why we also use Adjusted R², which accounts for the number of predictors.


📌 Example
Let’s say we’re predicting house prices using:

Size of the house
Location
Number of bedrooms

If our model gives R² = 0.90, it means:

🏠 90% of the variation in house prices is explained by these predictors.


⚠️ Limitations of R-Squared





















LimitationDescription❌ No CausationA high R² doesn’t mean predictors cause the outcome.📉 Misleading with Many PredictorsR² increases even with irrelevant variables.🔄 Not for Non-Linear ModelsR² assumes a linear relationship.

✅ Summary

R² measures model fit — how well your predictors explain the outcome.
Higher R² is better, but not always meaningful.
Use Adjusted R² for comparing models with different numbers of predictors.
